{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Preprocessing Pipeline Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/Users/manueljohn/Training/github-projects/bike-demand-prediction/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.components.data_cleaner import clean_col_names, NullValueImputer\n",
    "\n",
    "from src.components.feature_extractor import SkewDiscretizer, CategoricalEncoder, LagFeatureCreator\n",
    "from src.components.feature_extractor import extract_date_features, remove_multicollinear_features\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class PreProcessPipeline:\n",
    "    def __init__(self):\n",
    "        self.clean_col_transformer = None\n",
    "        self.null_value_imputer = None\n",
    "\n",
    "        self.skew_discretizer = None\n",
    "        self.multicollinear_transformer = None\n",
    "        self.categorical_encoder = None\n",
    "        self.date_features_transformer = None\n",
    "        self.lag_features_transformer = None\n",
    "\n",
    "        self.cleaning_pipeline = None\n",
    "        self.feature_transformer_pipeline = None\n",
    "        self.preprocessing_pipeline = None\n",
    "        \n",
    "    def create_cleaning_pipeline(self):\n",
    "        self.clean_col_transformer = FunctionTransformer(func=clean_col_names)\n",
    "        self.null_value_imputer = NullValueImputer()\n",
    "\n",
    "        self.cleaning_pipeline = Pipeline([\n",
    "            ('clean_col_transformer', self.clean_col_transformer), \n",
    "            ('imputer', self.null_value_imputer)])\n",
    "        \n",
    "        return self.cleaning_pipeline\n",
    "    \n",
    "    def create_feature_pipeline(self):\n",
    "        self.skew_discretizer = SkewDiscretizer()\n",
    "        self.multicollinear_transformer = FunctionTransformer(func=remove_multicollinear_features)\n",
    "        self.categorical_encoder = CategoricalEncoder()\n",
    "        self.date_features_transformer = FunctionTransformer(func=extract_date_features)\n",
    "        self.lag_features_transformer = LagFeatureCreator(lag_hours=24)\n",
    "\n",
    "        self.feature_transformer_pipeline = Pipeline([\n",
    "            ('skew_discretizer', self.skew_discretizer), \n",
    "            ('multicollinear_transformer', self.multicollinear_transformer), \n",
    "            ('categorical_encoder', self.categorical_encoder), \n",
    "            ('date_features_transformer', self.date_features_transformer), \n",
    "            ('lag_features_transformer', self.lag_features_transformer)\n",
    "            ])\n",
    "        \n",
    "        return self.feature_transformer_pipeline\n",
    "    \n",
    "    def get_preprocessing_pipeline(self):\n",
    "        self.create_cleaning_pipeline()\n",
    "        self.create_feature_pipeline()\n",
    "\n",
    "        self.preprocessing_pipeline = Pipeline([\n",
    "            ('cleaning_pipeline', self.cleaning_pipeline), \n",
    "            ('feature_transform_pipeline', self.feature_transformer_pipeline)\n",
    "            ])\n",
    "        \n",
    "        return self.preprocessing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 14)\n",
      "(6984, 40)\n"
     ]
    }
   ],
   "source": [
    "import cloudpickle\n",
    "\n",
    "def save_pipeline_components(pipeline_obj, transformer_root, pipeline_root):\n",
    "    transformer_directory = os.path.dirname(transformer_root)\n",
    "    pipeline_directory = os.path.dirname(pipeline_root)\n",
    "\n",
    "    os.makedirs(transformer_directory, exist_ok=True), os.makedirs(pipeline_directory, exist_ok=True)\n",
    "\n",
    "    for key in pipeline_obj.__dict__.keys():\n",
    "        if type(pipeline_obj.__dict__[key]) != Pipeline:\n",
    "            with open(f\"{transformer_root}/{key}.pkl\", 'wb') as f:\n",
    "                cloudpickle.dump(pipeline_obj.__dict__[key], f)\n",
    "\n",
    "        else:\n",
    "            with open(f\"{pipeline_root}/{key}.pkl\", 'wb') as f:\n",
    "                cloudpickle.dump(pipeline_obj.__dict__[key], f)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/Users/manueljohn/Training/github-projects/bike-demand-prediction/artifacts/raw_data/train_data.csv')\n",
    "feature_pipeObj = PreProcessPipeline()\n",
    "feature_pipe = feature_pipeObj.get_preprocessing_pipeline()\n",
    "print(data.shape)\n",
    "\n",
    "data = feature_pipe.fit_transform(data)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "save_pipeline_components(feature_pipeObj, pipeline_root='/Users/manueljohn/Training/github-projects/bike-demand-prediction/artifacts/pipeline-components/'\n",
    "                         , transformer_root='/Users/manueljohn/Training/github-projects/bike-demand-prediction/artifacts/transformer-components/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
